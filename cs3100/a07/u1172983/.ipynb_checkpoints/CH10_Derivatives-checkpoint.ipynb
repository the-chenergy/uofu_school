{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Derivatives\n",
    "\n",
    "# Cells that help you with your questions in Asg-7 are AT THE VERY END\n",
    "  \n",
    "\n",
    "## You may wish to watch the video before embarking on this work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# This Youtube video walks through this notebook\n",
    "\n",
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('xGvCjoWemWg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    " ## The CFG for REs used in this exercise is below\n",
    "\n",
    "\n",
    "expression -> expression PLUS catexp\n",
    "\n",
    "catexp -> catexp andexp | andexp \n",
    "\n",
    "andexp -> andexp AND ordyexp | ordyexp\n",
    "\n",
    "ordyexp -> str | eps | LPAREN expression RPAREN | ordyexp STAR | NOT ordyexp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You may use any of these help commands:\n",
      "help(ResetStNum)\n",
      "help(NxtStateStr)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "import sys\n",
    "\n",
    "# -- Detect if in Own Install or in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    OWN_INSTALL = False\n",
    "except:\n",
    "    OWN_INSTALL = True\n",
    "    \n",
    "if OWN_INSTALL:\n",
    "    \n",
    "  #---- Leave these definitions ON if running on laptop\n",
    "  #---- Else turn OFF by putting them between ''' ... '''\n",
    "\n",
    "  sys.path[0:0] = ['../../../../..',  '../../../../../3rdparty',  \n",
    "                   '../../../..',  '../../../../3rdparty',  \n",
    "                   '../../..',     '../../../3rdparty', \n",
    "                   '../..',        '../../3rdparty',\n",
    "                   '..',           '../3rdparty' ]\n",
    "\n",
    "else: # In colab\n",
    "  ! if [ ! -d Jove ]; then git clone https://github.com/ganeshutah/Jove Jove; fi\n",
    "  sys.path.append('./Jove')\n",
    "  sys.path.append('./Jove/jove')\n",
    "\n",
    "# -- common imports --\n",
    "from jove.lex import lex\n",
    "from jove.yacc import yacc\n",
    "from jove.StateNameSanitizers import ResetStNum, NxtStateStr\n",
    "from jove.SystemImports       import *\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Token definitions\n",
    "\n",
    "This is the lexer for REs. We begin with token definitions\n",
    "\n",
    "**NOTE** \n",
    "\n",
    "### * We leave it as an exercise for you to add the token for negation and conjunction\n",
    "\n",
    "### i.e. support things like !a for negation and !a & b for conjunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "tokens = ('EPS','STR','LPAREN','RPAREN','PLUS','STAR', 'NOT', 'AND')\n",
    "\n",
    "# Tokens\n",
    "t_PLUS    = r'\\+'\n",
    "t_STAR    = r'\\*'\n",
    "t_LPAREN  = r'\\('\n",
    "t_RPAREN  = r'\\)'\n",
    "t_EPS     = r'\\'\\'|\\\"\\\"'  \n",
    "t_STR     = r'[a-zA-Z0-9]'\n",
    "\n",
    "t_NOT     = r'\\!' # <== pattern for NOT  - new to RE\n",
    "t_AND     = r'\\&' # <== pattern for AND  - new to RE\n",
    "\n",
    "# Ignored characters\n",
    "t_ignore = \" \\t\"\n",
    "\n",
    "def t_newline(t):\n",
    "    r'\\n+'\n",
    "    t.lexer.lineno += t.value.count(\"\\n\")\n",
    "    \n",
    "def t_error(t):\n",
    "    print(\"Illegal character '%s'\" % t.value[0])\n",
    "    t.lexer.skip(1)\n",
    "    \n",
    "# Build the lexer, if necessary, right here.\n",
    "# lex()  #-- not needed for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### These parsing rules specify many things. \n",
    "\n",
    "We begin with operator precedence rules that are essentially to help the \"LALR parser\" (also known as the bottom-up parser) resolve 'shift-reduce conflicts'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Parsing rules\n",
    "\n",
    "# A4J: Suggested new precedence rules for AND and NOT are in comments below.\n",
    "# Uncomment the AND and NOT lines in your extension\n",
    "# \n",
    "precedence = (\n",
    "   ('left','PLUS'),\n",
    "   ('left', 'AND'),   #<== Note where AND sits\n",
    "   ('left','STAR'),\n",
    "   ('right','NOT')    #<== Note where NOT sits\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## CFG productions and semantic actions\n",
    "\n",
    "These Python functions whose names begin with \"p_\" house (1) the CFG production rules within their documentation strings. (2) the semantic actions within their body. The semantic actions can refer to grammar symbol attributes within CFG productions. We will explain one of these rules now.\n",
    "\n",
    "Take the rules \n",
    "\n",
    " expression -> expression PLUS catexp\n",
    " expression -> catexp\n",
    " \n",
    "1) This function defines the first production rule\n",
    "\n",
    "def p_expression_plus(t):\n",
    "\n",
    "   a) This comment string expresses the production rule\n",
    "   \n",
    "    '''expression : expression PLUS catexp'''\n",
    "    \n",
    "   b) This line below tells us that the occurrence of 'expression' on\n",
    "      the left-hand side is marked t[0], and its value is determined by\n",
    "      applying function attrDyadicInfix onto its three arguments below.\n",
    "      Here, t[1] is the attribute of 'expression' coming after the colon (:)\n",
    "      and the attribute of catexp is t[3]\n",
    "      \n",
    "    t[0] = attrDyadicInfix(\"+\", t[1], t[3])    \n",
    "    \n",
    "2) This function expresses the second related production rule where the\n",
    "   basis case \n",
    "    \n",
    "def p_expression_plus1(t):\n",
    "    '''expression : catexp'''\n",
    "\n",
    "    t[0] = t[1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def p_expression_plus(t):\n",
    "    'expression : expression PLUS catexp'\n",
    "    #\n",
    "    t[0] = attrDyadicInfix(\"+\", t[1], t[3])    \n",
    "    \n",
    "def p_expression_plus1(t):\n",
    "    'expression : catexp'\n",
    "    #\n",
    "    t[0] = t[1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def p_expression_cat(t):\n",
    "    'catexp :  catexp andexp'\n",
    "    #\n",
    "    t[0] = attrDyadicInfix(\".\", t[1], t[2])\n",
    "\n",
    "def p_expression_cat1(t):\n",
    "    'catexp :  andexp'\n",
    "    #\n",
    "    t[0] = t[1]  \n",
    "\n",
    "def p_expression_ordy(t):          #<== CHECK THESE  \n",
    "    'andexp : andexp AND ordyexp'  #<==  \n",
    "    #\n",
    "    t[0] = attrDyadicInfix(\"&\", t[1], t[3])\n",
    "\n",
    "\n",
    "def p_expression_ordy1(t):\n",
    "    'andexp : ordyexp'\n",
    "    #\n",
    "    t[0] = t[1]\n",
    "    \n",
    "\n",
    "# We employ field 'ast' of the dict to record the abstract syntax tree. \n",
    "# Field 'dig' holds a digraph. It too is a dict. \n",
    "# Its fields are nl for the node list and el for the edge list\n",
    "\n",
    "def p_expression_ordy_star(t):\n",
    "    'ordyexp : ordyexp STAR'\n",
    "    #\n",
    "    ast = ('*', t[1]['ast'])\n",
    "\n",
    "    nlin = t[1]['dig']['nl']\n",
    "    elin = t[1]['dig']['el']\n",
    "    \n",
    "    rootin = nlin[0]\n",
    "\n",
    "    root = NxtStateStr(\"R*_\") \n",
    "    right = NxtStateStr(\"*_\")\n",
    "\n",
    "    t[0] = {'ast' : ast,\n",
    "            'dig' : {'nl' : [root] + nlin + [right], # this order important for proper layout!\n",
    "                     'el' : elin + [ (root, rootin),\n",
    "                                     (root, right) ]\n",
    "                    }}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "def p_expression_ordy_not(t):     #<== Note how we added NOT\n",
    "    'ordyexp : NOT ordyexp'\n",
    "    #\n",
    "    ast  = ('!', t[2]['ast'])\n",
    "    \n",
    "    nlin = t[2]['dig']['nl']\n",
    "    elin = t[2]['dig']['el']\n",
    "    \n",
    "    rootin = nlin[0]\n",
    "\n",
    "    root = NxtStateStr(\"!R_\") \n",
    "    left = NxtStateStr(\"!_\")\n",
    "\n",
    "    t[0] = {'ast' : ast,\n",
    "            'dig' : {'nl' : [ root, left ] + nlin, # this order important for proper layout!\n",
    "                     'el' : elin + [ (root, left),\n",
    "                                     (root, rootin) ]\n",
    "                    }}\n",
    "\n",
    "\n",
    "\n",
    "def p_expression_ordy_paren(t):\n",
    "    'ordyexp : LPAREN expression RPAREN'\n",
    "    #\n",
    "    ast  = t[2]['ast']\n",
    "    \n",
    "    nlin = t[2]['dig']['nl']\n",
    "    elin = t[2]['dig']['el']\n",
    "    \n",
    "    rootin = nlin[0]\n",
    "    \n",
    "    root = NxtStateStr(\"(R)_\")\n",
    "    left = NxtStateStr(\"(_\")\n",
    "    right= NxtStateStr(\")_\")\n",
    "    \n",
    "    t[0] = {'ast' : ast,\n",
    "            'dig' : {'nl' : [root, left] + nlin + [right], \n",
    "                     'el' : elin + [ (root, left),\n",
    "                                     (root, rootin),\n",
    "                                     (root, right) ]\n",
    "                    }}\n",
    "\n",
    "def p_expression_ordy_eps(t):\n",
    "    'ordyexp : EPS'\n",
    "    #\n",
    "    strn = '@'\n",
    "    ast  = ('@', strn)           \n",
    "    t[0] = { 'ast' : ast,\n",
    "             'dig' : {'nl' : [ strn + NxtStateStr(\"_\") ],\n",
    "                      'el' : []\n",
    "                     }}          \n",
    "    \n",
    "def p_expression_ordy_str(t):\n",
    "    'ordyexp : STR'\n",
    "    #\n",
    "    strn = t[1]\n",
    "    ast  = ('str', strn)\n",
    "    t[0] = {'ast' : ast,\n",
    "            'dig' : {'nl' : [ strn + NxtStateStr(\"_\") ],\n",
    "                     'el' : [] \n",
    "                    }}\n",
    "\n",
    "def p_error(t):\n",
    "    print(\"Syntax error at '%s'\" % t.value)\n",
    "\n",
    "#--\n",
    "    \n",
    "def attrDyadicInfix(op, attr1, attr3):         # <== this is what prints the parse-tree\n",
    "    ast  = (op, (attr1['ast'], attr3['ast']))  # <== for an infix operator\n",
    "    \n",
    "    nlin1 = attr1['dig']['nl']\n",
    "    nlin3 = attr3['dig']['nl']\n",
    "    nlin  = nlin1 + nlin3\n",
    "    \n",
    "    elin1 = attr1['dig']['el']\n",
    "    elin3 = attr3['dig']['el']\n",
    "    elin  = elin1 + elin3\n",
    "    \n",
    "    rootin1 = nlin1[0]\n",
    "    rootin3 = nlin3[0]    \n",
    "    \n",
    "    root   = NxtStateStr(\"R1\"+op+\"R2\"+\"_\") # NxtStateStr(\"$_\")\n",
    "    left   = rootin1\n",
    "    middle = NxtStateStr(op+\"_\")\n",
    "    right  = rootin3\n",
    "    \n",
    "    return {'ast' : ast,\n",
    "            'dig' : {'nl' : [ root, left, middle, right ] + nlin,\n",
    "                     'el' : elin + [ (root, left),\n",
    "                                     (root, middle),\n",
    "                                     (root, right) ]\n",
    "                     }}\n",
    "\n",
    "#===\n",
    "# This is the main function in this Jove file. Give\n",
    "#===\n",
    "\n",
    "def parseRE(s):\n",
    "    \"\"\"In: a string s containing a regular expression.\n",
    "       Out: An attribute triple consisting of\n",
    "            1) An abstract syntax tree suitable for processing in the derivative-based scanner\n",
    "            2) A node-list for the parse-tree digraph generated. Good for drawing a parse tree \n",
    "               using the drawPT function below\n",
    "            3) An edge list for the parse-tree generated (again good for drawing using the\n",
    "               drawPT function below)\n",
    "    \"\"\"\n",
    "    mylexer  = lex()\n",
    "    myparser = yacc()\n",
    "    pt = myparser.parse(s, lexer = mylexer)             # <== pass the right lexer into the parser\n",
    "    return (pt['ast'], pt['dig']['nl'], pt['dig']['el']) # <== the parser returns the parse-tree\n",
    "                                                        # <== as a Python data structure, plus a tree data structure for drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def drawPT(ast_nl_el, comment=\"PT\"):\n",
    "    \"\"\"Given an (ast, nl, el) triple where nl is the node and el the edge-list,\n",
    "       draw the Parse Tree by returning a dot object.\n",
    "    \"\"\"\n",
    "    (ast, nl, el) = ast_nl_el\n",
    "    print(\"Drawing AST for \", ast)\n",
    "    dotObj_pt = Digraph(comment)\n",
    "    dotObj_pt.graph_attr['rankdir'] = 'TB'\n",
    "    for n in nl:\n",
    "        prNam = n.split('_')[0]\n",
    "        dotObj_pt.node(n, prNam, shape=\"oval\", peripheries=\"1\")\n",
    "    for e in el:\n",
    "        dotObj_pt.edge(e[0], e[1])\n",
    "    return dotObj_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# You can draw parse-trees as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "drawPT(parseRE(\"0+11*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# You can draw parse-trees with & and ! also  \n",
    "## Notice how the concatenation works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawPT(parseRE(\"a !b*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More parse-tree drawings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawPT(parseRE(\"c d & e f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RE with & and + involved : \"a + b & c + d\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawPT(parseRE(\"a + b & c + d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RE with & and + involved : \"a + !b & !c + d\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawPT(parseRE(\"a + !b & !c + d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Derivative-based Pattern Matching\n",
    "\n",
    "## You will now be given a derivative-based pattern matcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#=== Now comes derivMatch as illustration of RE Derivative scanning\n",
    "\n",
    "# These four functions are simple extractors of the operator and arguments\n",
    "\n",
    "def opr(E):\n",
    "    \"\"\"Retrieves the operator of an expression.\n",
    "    \"\"\"\n",
    "    return E[0]\n",
    "\n",
    "def arg1(E):\n",
    "    \"\"\"Retrieves the first argument of a binary operator-based expression.\n",
    "    \"\"\"\n",
    "    return E[1][0]\n",
    "\n",
    "def arg2(E):\n",
    "    \"\"\"Retrieves the second argument of a binary operator-based expression.\n",
    "    \"\"\"\n",
    "    return E[1][1]\n",
    "\n",
    "def arg(E):\n",
    "    \"\"\"Retrieves the only argument of a unary operator-based expression.\n",
    "    \"\"\"\n",
    "    return E[1]\n",
    "\n",
    "def nullable(E):\n",
    "    \"\"\"This is the nullability test defined in Chapter 10.\n",
    "    \"\"\"\n",
    "    if (opr(E) == \"str\") :\n",
    "        return False\n",
    "    elif (opr(E) == '@') :\n",
    "        return True\n",
    "    elif (opr(E) == \"mty\") :\n",
    "        return False\n",
    "    elif (opr(E) == \"*\"):\n",
    "        return True\n",
    "    elif (opr(E) == \"!\"):                             # <== See how ! is handled\n",
    "        return not nullable(arg(E))\n",
    "    elif (opr(E) == '+') :\n",
    "        return nullable(arg1(E)) or nullable(arg2(E))\n",
    "    elif (opr(E) == '.') :\n",
    "        return nullable(arg1(E)) and nullable(arg2(E))\n",
    "    elif (opr(E) == '&') :                            #  <== See how & is handled\n",
    "        return nullable(arg1(E)) and nullable(arg2(E))\n",
    "    else:\n",
    "        return \"???\"    \n",
    "\n",
    "def dv(E, c):\n",
    "    \"\"\"This function computes the derivative\n",
    "       of a regular expression E with respect\n",
    "       to character \"c\".\n",
    "    \"\"\"\n",
    "    if (opr(E) == \"str\") :\n",
    "        if (arg(E) == c):\n",
    "            return ('@', '@')\n",
    "        else:\n",
    "            return (\"mty\", \"mty\")\n",
    "    elif (opr(E) == '@') :\n",
    "        return (\"mty\", \"mty\")\n",
    "    elif (opr(E) == \"mty\") :\n",
    "        return (\"mty\", \"mty\")\n",
    "    elif (opr(E) == \"*\"):\n",
    "        return (\".\", (dv(arg(E), c), E))\n",
    "    elif (opr(E) == \"!\"):\n",
    "        return (\"!\", dv(arg(E), c))\n",
    "    elif (opr(E) == '+') :\n",
    "        return (\"+\", (dv(arg1(E), c), dv(arg2(E), c)))\n",
    "    elif (opr(E) == '&') :\n",
    "        return (\"&\", (dv(arg1(E), c), dv(arg2(E), c)))\n",
    "    elif (opr(E) == '.') :\n",
    "        if nullable(arg1(E)):\n",
    "            return (\"+\", ( ('.', (dv(arg1(E), c), arg2(E))), dv(arg2(E), c) ))\n",
    "        else:\n",
    "            return ('.', (dv(arg1(E), c), arg2(E)))\n",
    "    else:\n",
    "        return \"???\"        \n",
    "\n",
    "def matches(w, E):\n",
    "    if w==\"\":\n",
    "        return nullable(E)\n",
    "    else:\n",
    "        derivative = dv(E, w[0])\n",
    "        return matches(w[1:], derivative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us now test pattern-matching using derivatives\n",
    "\n",
    "## USAGE\n",
    "\n",
    "## 1) Obtain RE = someRE\n",
    "\n",
    "## 2) DO this: (ast, nl, el) = parseRE(RE)\n",
    "\n",
    "## 3) CHECK nullable(ast)\n",
    "\n",
    "## 4) CHECK matches(string, ast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Testing Derivative-based Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Testing Nullability\n",
    "\n",
    "A regular expression is nullable if its language contains epsilon.\n",
    "Regular-expression based pattern-matching works as follows:\n",
    "\n",
    "* Keep obtaining the derivatives of a given RE under the characters comprising a string\n",
    "\n",
    "* When the string is empty, check whether the RE is nullable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is '' nullable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Returns the Python expression E as a tree\n",
    "# Also returns the node list nl\n",
    "# and the edge list el\n",
    "\n",
    "(E, nl, el) = parseRE(\"''\")\n",
    "nullable(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is \"c\" nullable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "(E, nl, el) = parseRE(\"c\")\n",
    "nullable(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Is c* nullable?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(E, nl, el) = parseRE(\"c*\")\n",
    "nullable(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE1 = \"(a+bc+def+bd)\"\n",
    "ast1_n1_e1 = parseRE(RE1)\n",
    "(ast1, n1, e1) = ast1_n1_e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nullable(ast1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## More pattern-matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches(\"def\", ast1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE2 = \"!(a+bc+def+bd)\"\n",
    "ast2_n2_e2 = parseRE(RE2)\n",
    "(ast2, n2, e2) = ast2_n2_e2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST Pattern Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE2 = \"!(a+bc+def+bd)\"\n",
    "ast2_n2_e2 = parseRE(RE2)\n",
    "(ast2, n2, e2) = ast2_n2_e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches(\"de\", ast2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE3 = \"(a+bc)&(bc+d)\"\n",
    "(ast3,n3,e3) = parseRE(RE3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches(\"bc\", ast3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE4 = \"(a+bc+def+bd)*\"\n",
    "(ast4, n4, e4) = parseRE(RE4)\n",
    "matches(\"bcbcbdadef\", ast4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE5 = \"(a+!b)*\"\n",
    "(ast5, n5, e5) = parseRE(RE5)\n",
    "matches(\"acca\", ast5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELLS THAT HELP YOU WITH ASG-7 are below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine whether ```(c* & !b)``` is nullable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** YOUR CODE HERE ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine whether ```(c* & b*)``` is nullable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** YOUR CODE HERE ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine (through analytical derivation) whether \n",
    "## ```(a+bc+def+bd)*``` matches the string ```bc```\n",
    "\n",
    "# THEN TEST it out also, below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** YOUR CODE HERE ***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
