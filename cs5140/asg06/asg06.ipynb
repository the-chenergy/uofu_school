{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "$\\text{}$\n",
    "\n",
    "$$\\LARGE\\text{Assignment: Regression}$$\n",
    "\n",
    "$$\\large\\text{Qianlang Chen (u1172983)}$$\n",
    "\n",
    "$$\\text{CS 5140 Spring 2021}$$\n",
    "\n",
    "$\\text{}$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(100, 50) (100,) (50, 20) (50,)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "X = numpy.loadtxt('./data/X.csv', delimiter=',')\n",
    "y = numpy.loadtxt('./data/y.csv', delimiter=',')\n",
    "M = numpy.loadtxt('./data/M.csv', delimiter=',')\n",
    "W = numpy.loadtxt('./data/W.csv', delimiter=',')\n",
    "print(X.shape, y.shape, M.shape, W.shape)"
   ]
  },
  {
   "source": [
    "# Problem 1\n",
    "\n",
    "## Part A"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg\n",
    "\n",
    "def least_squares(X, y): return linalg.inv(X.T @ X) @ X.T @ y.T\n",
    "\n",
    "def ridge(X, y, s):\n",
    "    return (linalg.inv(X.T @ X + s * numpy.identity(X.shape[1]))\n",
    "            @ X.T @ y.T)\n",
    "\n",
    "def sse(X, y, alpha): return linalg.norm(y.T - X @ alpha, 2)"
   ]
  },
  {
   "source": [
    "#### Using Least Squares:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error: 3.452257117069318\n"
     ]
    }
   ],
   "source": [
    "alpha = least_squares(X, y)\n",
    "print(f'Error: {sse(X, y, alpha)}')"
   ]
  },
  {
   "source": [
    "#### Using Ridge Regression:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error with s = 0.1: 3.697108163766999\nError with s = 0.3: 3.9003300572591115\nError with s = 0.7: 4.198778810955157\nError with s = 0.9: 4.327017561622948\nError with s = 1.1: 4.445519765867784\nError with s = 1.3: 4.555758705764217\nError with s = 1.5: 4.658819389955557\n"
     ]
    }
   ],
   "source": [
    "S = [.1, .3, .7, .9, 1.1, 1.3, 1.5]\n",
    "for s in S:\n",
    "    alpha = ridge(X, y, s)\n",
    "    print(f'Error with s = {s}: {sse(X, y, alpha)}')"
   ]
  },
  {
   "source": [
    "## Part B"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(X_learn, y_learn, X_test, y_test, regression, *args):\n",
    "    alpha = regression(X_learn, y_learn, *args)\n",
    "    return sse(X_test, y_test, alpha)\n",
    "\n",
    "X1, X1_r = X[:75, :], X[75:, :]\n",
    "y1, y1_r = y[:75], y[75:]\n",
    "X2, X2_r = X[25:, :], X[:25, :]\n",
    "y2, y2_r = y[25:], y[:25]\n",
    "X3, X3_r = (numpy.vstack((X[:50, :], X[75:, :])),\n",
    "            numpy.vstack((X[50:, :], X[:75, :])))\n",
    "y3, y3_r = (numpy.concatenate((y[:50], y[75:])),\n",
    "            numpy.concatenate((y[50:], y[:75])))\n",
    "X4, X4_r = (numpy.vstack((X[:25, :], X[50:, :])),\n",
    "            numpy.vstack((X[25:, :], X[:50, :])))\n",
    "y4, y4_r = (numpy.concatenate((y[:25], y[50:])),\n",
    "            numpy.concatenate((y[25:], y[:50])))"
   ]
  },
  {
   "source": [
    "#### Using Least Squares:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error of (X1, y1): 4.574549134311085\nError of (X2, y2): 3.953705254240132\nError of (X3, y3): 6.530782116788326\nError of (X4, y4): 6.035430316733807\n"
     ]
    }
   ],
   "source": [
    "print('Error of (X1, y1):'\n",
    "      f' {cross_validate(X1, y1, X1_r, y1_r, least_squares)}')\n",
    "print('Error of (X2, y2):'\n",
    "      f' {cross_validate(X2, y2, X2_r, y2_r, least_squares)}')\n",
    "print('Error of (X3, y3):'\n",
    "      f' {cross_validate(X3, y3, X3_r, y3_r, least_squares)}')\n",
    "print('Error of (X4, y4):'\n",
    "      f' {cross_validate(X4, y4, X4_r, y4_r, least_squares)}')"
   ]
  },
  {
   "source": [
    "#### Using Ridge Regression:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "With s = 0.1:\n    Error of (X1, y1): 2.9032557648579354\n    Error of (X2, y2): 2.435781393405244\n    Error of (X3, y3): 4.6434346141632625\n    Error of (X4, y4): 4.710580539545258\n\nWith s = 0.3:\n    Error of (X1, y1): 2.812360286833187\n    Error of (X2, y2): 2.4362818335730734\n    Error of (X3, y3): 4.730067190162512\n    Error of (X4, y4): 4.661613787246709\n\nWith s = 0.7:\n    Error of (X1, y1): 2.871140069262489\n    Error of (X2, y2): 2.6205294719938363\n    Error of (X3, y3): 4.97388233930467\n    Error of (X4, y4): 4.929031986533713\n\nWith s = 0.9:\n    Error of (X1, y1): 2.918800501686161\n    Error of (X2, y2): 2.7029498819203344\n    Error of (X3, y3): 5.096898305781339\n    Error of (X4, y4): 5.081521304441042\n\nWith s = 1.1:\n    Error of (X1, y1): 2.966809395453503\n    Error of (X2, y2): 2.77732331042384\n    Error of (X3, y3): 5.216001290132486\n    Error of (X4, y4): 5.229960096653861\n\nWith s = 1.3:\n    Error of (X1, y1): 3.0131279773121937\n    Error of (X2, y2): 2.844756655775371\n    Error of (X3, y3): 5.330009084973331\n    Error of (X4, y4): 5.37183849586043\n\nWith s = 1.5:\n    Error of (X1, y1): 3.057072486774334\n    Error of (X2, y2): 2.9062788229288645\n    Error of (X3, y3): 5.438507513046232\n    Error of (X4, y4): 5.506437349184852\n\n"
     ]
    }
   ],
   "source": [
    "for s in S:\n",
    "    print(f'With s = {s}:')\n",
    "    print('    Error of (X1, y1):'\n",
    "          f' {cross_validate(X1, y1, X1_r, y1_r, ridge, s)}')\n",
    "    print('    Error of (X2, y2):'\n",
    "          f' {cross_validate(X2, y2, X2_r, y2_r, ridge, s)}')\n",
    "    print('    Error of (X3, y3):'\n",
    "          f' {cross_validate(X3, y3, X3_r, y3_r, ridge, s)}')\n",
    "    print('    Error of (X4, y4):'\n",
    "          f' {cross_validate(X4, y4, X4_r, y4_r, ridge, s)}')\n",
    "    print('')"
   ]
  },
  {
   "source": [
    "## Part C\n",
    "\n",
    "It looks like Ridge Regression with $s = 0.3$ worked the best out of these options (3.66 average error across the four splits)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}