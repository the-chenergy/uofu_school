{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "$\\text{}$\n",
    "\n",
    "$$\\LARGE\\text{Assignment: Frequent Items}$$\n",
    "\n",
    "$$\\large\\text{Qianlang Chen (u1172983)}$$\n",
    "\n",
    "$$\\text{CS 5140 Spring 2021}$$\n",
    "\n",
    "$\\text{}$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4000000 5000000\n"
     ]
    }
   ],
   "source": [
    "S1 = open('data/S1.txt').read().strip()\n",
    "S2 = open('data/S2.txt').read().strip()\n",
    "print(len(S1), len(S2))"
   ]
  },
  {
   "source": [
    "# Problem 1\n",
    "\n",
    "## Part A"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Summary of S1:\n",
      "    Frequent characters:\n",
      "\tchar\tfreq\tratio\n",
      "\tj\t1\t0.0000\n",
      "\tb\t639426\t0.1599\n",
      "\ta\t1840126\t0.4600\n",
      "\tc\t240652\t0.0602\n",
      "\to\t1\t0.0000\n",
      "\ti\t1\t0.0000\n",
      "\tv\t1\t0.0000\n",
      "\n",
      "    Characters that must've occurred at least 30.0% of the time:\n",
      "\ta\n",
      "\n",
      "    Characters that might've occurred at least 20.0% of the time:\n",
      "\tb\n",
      "\n",
      "Summary of S2:\n",
      "    Frequent characters:\n",
      "\tchar\tfreq\tratio\n",
      "\tj\t1\t0.0000\n",
      "\tb\t757426\t0.1515\n",
      "\ta\t2068126\t0.4136\n",
      "\tc\t398652\t0.0797\n",
      "\th\t1\t0.0000\n",
      "\tw\t1\t0.0000\n",
      "\tr\t1\t0.0000\n",
      "\n",
      "    Characters that must've occurred at least 40.0% of the time:\n",
      "\ta\n",
      "\n",
      "    Characters that might've occurred at least 50.0% of the time:\n",
      "\ta\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Runs the Misra-Gries Algorithm on stream `S` using (`k` - 1)\n",
    "# counters. Returns (the labels, the counts).\n",
    "def misra_gries(S, k):\n",
    "    L = [None] * (k - 1)\n",
    "    C = [0] * (k - 1)\n",
    "    for x in S:\n",
    "        if x in L:\n",
    "            C[L.index(x)] += 1\n",
    "        else:\n",
    "            if 0 in C:\n",
    "                j = C.index(0)\n",
    "                L[j] = x\n",
    "                C[j] = 1\n",
    "            else:\n",
    "                for j in range(k - 1): C[j] -= 1\n",
    "    return L, C\n",
    "\n",
    "def misra_gries_summarize(name, S, k, must, might):\n",
    "    m = len(S)\n",
    "    L, C = misra_gries(S, k)\n",
    "    print(f'Summary of {name}:\\n'\n",
    "          '    Frequent characters:\\n'\n",
    "          '\\tchar\\tfreq\\tratio')\n",
    "    for j in range(k - 1): print(f'\\t{L[j]}\\t{C[j]}\\t{C[j] / m:.4f}')\n",
    "    X_must = {L[j] for j in range(k - 1) if C[j] / m >= must}\n",
    "    print('\\n'\n",
    "          f'    Characters that must\\'ve occurred at least {must:.1%}'\n",
    "          ' of the time:')\n",
    "    print('\\t' + ', '.join(X_must))\n",
    "    X_might = {L[j] for j in range(k - 1) if C[j] / m + 1 / k >= might}\n",
    "    if might <= must: X_might -= X_must\n",
    "    print('\\n'\n",
    "          f'    Characters that might\\'ve occurred at least {might:.1%}'\n",
    "          ' of the time:')\n",
    "    print('\\t' + ', '.join(X_might))\n",
    "    print('')\n",
    "\n",
    "misra_gries_summarize('S1', S1, 8, .3, .2)\n",
    "misra_gries_summarize('S2', S2, 8, .4, .5)"
   ]
  },
  {
   "source": [
    "## Part B"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Summary of S1:\n",
      "    Looked-up characters:\n",
      "\tchar\tfreq\tratio\n",
      "\ta\t2000100\t0.5\n",
      "\tb\t879068\t0.2198\n",
      "\tc\t440626\t0.1102\n",
      "\n",
      "    Characters that must've occurred 20.0% of the time:\n",
      "\ta\n",
      "\n",
      "    Characters that might've occurred 20.0% of the time:\n",
      "\tb\n",
      "\n",
      "Summary of S2:\n",
      "    Looked-up characters:\n",
      "\tchar\tfreq\tratio\n",
      "\ta\t2290100\t0.458\n",
      "\tb\t1085738\t0.2171\n",
      "\tc\t687536\t0.1375\n",
      "\n",
      "    Characters that must've occurred 20.0% of the time:\n",
      "\ta\n",
      "\n",
      "    Characters that might've occurred 20.0% of the time:\n",
      "\tb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "t = 6\n",
    "k = 8\n",
    "salts = [chr(random.randint(0, 127)) for _ in range(t)]\n",
    "\n",
    "# Hashes an object `x` using the hash function h_`j` with output space\n",
    "# [0, k).\n",
    "def h(x, j): return hash(x + salts[j]) % k\n",
    "\n",
    "# Runs Count-Min Sketch on stream `S` using `t` hashing algorithms.\n",
    "# Returns the 2D-array of counters.\n",
    "def count_min(S):\n",
    "    C = [[0] * k for _ in range(t)]\n",
    "    for x in S:\n",
    "        for j in range(t): C[j][h(x, j)] += 1\n",
    "    return C\n",
    "\n",
    "def count_min_freq(C, x): return min(C[j][h(x, j)] for j in range(t))\n",
    "\n",
    "def count_min_summarize(name, S, lookup_chars, all_chars, must, might):\n",
    "    m = len(S)\n",
    "    C = count_min(S)\n",
    "    print(f'Summary of {name}:\\n'\n",
    "          '    Looked-up characters:\\n'\n",
    "          '\\tchar\\tfreq\\tratio')\n",
    "    for x in lookup_chars:\n",
    "        f = count_min_freq(C, x)\n",
    "        print(f'\\t{x}\\t{f}\\t{f / m:.4}')\n",
    "    X_must = {x for x in all_chars\n",
    "                if count_min_freq(C, x) / m - 2 / k >= must}\n",
    "    print('\\n'\n",
    "          f'    Characters that must\\'ve occurred {must:.1%} of the'\n",
    "          ' time:')\n",
    "    print('\\t' + ', '.join(X_must))\n",
    "    X_might = {x for x in all_chars\n",
    "                 if count_min_freq(C, x) / m >= might}\n",
    "    if might <= must: X_might -= X_must\n",
    "    print('\\n'\n",
    "          f'    Characters that might\\'ve occurred {might:.1%} of the'\n",
    "          ' time:')\n",
    "    print('\\t' + ', '.join(X_might))\n",
    "    print('')\n",
    "\n",
    "count_min_summarize(\n",
    "    'S1', S1, 'abc', 'abcdefghijklmnopqrstuvwxyz', .2, .2)\n",
    "count_min_summarize(\n",
    "    'S2', S2, 'abc', 'abcdefghijklmnopqrstuvwxyz', .2, .2)"
   ]
  },
  {
   "source": [
    "## Part C\n",
    "\n",
    "We could still perform the algorithms mostly the same way, except now we'd like to treat the words as case-insensitive (by casting all letters into lowercase) and split up the words (by buffering the characters until receiving one or more whitespace characters). The objects in the stream would now be strings individual characters, which our labels or hash functions would also need to support.\n",
    "\n",
    "## Part D\n",
    "\n",
    "Count-Min Sketch provides upperbounds to the frequences for the queries, which is useful when we don't want to overestimate the frequency of anything or when overestimating frequencies have serious consequences."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}